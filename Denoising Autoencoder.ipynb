{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import Reshape, Conv2DTranspose, UpSampling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,_) , (x_test , _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b82bf3c18>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(x_train[1,:,:] , shape = (1,28,28) , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(loc=0, scale=1, size=x_train.shape)\n",
    "x_train_noisy = x_train + noise\n",
    "noise = np.random.normal(loc=0, scale=1, size=x_test.shape)\n",
    "x_test_noisy = x_test + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b82bcf860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise_plot = x_train_noisy[1,:,:] - x_train[1,:,:]\n",
    "plt.imshow(noise_plot , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(loc=0, scale=1, size=x_train.shape)\n",
    "x_train_noisy = x_train + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "latent_dim = 16\n",
    "act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(8 , 3 , input_shape = (28,28,1)))\n",
    "model.add(Activation(act))\n",
    "\n",
    "model.add(Conv2D(16 , 3))\n",
    "model.add(Activation(act))\n",
    "\n",
    "model.add(Conv2D(32 , 3))\n",
    "model.add(Activation(act))\n",
    "\n",
    "model.add(Conv2D(64,3))\n",
    "model.add(Activation(act))\n",
    "\n",
    "model.add(Conv2DTranspose(64,3))\n",
    "model.add(Activation(act))\n",
    "\n",
    "model.add(Conv2DTranspose(16,3))\n",
    "model.add(Activation(act))\n",
    "\n",
    "model.add(Conv2DTranspose(8,3))\n",
    "model.add(Activation(act))\n",
    "\n",
    "model.add(Conv2DTranspose(1,3))\n",
    "model.add(Activation(act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 22, 22, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 24, 24, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 26, 26, 8)         1160      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         73        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 71,777\n",
      "Trainable params: 71,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse' , optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0353\n",
      "Epoch 2/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0327\n",
      "Epoch 3/10000\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0320\n",
      "Epoch 4/10000\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0316\n",
      "Epoch 5/10000\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0313\n",
      "Epoch 6/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0312\n",
      "Epoch 7/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0310\n",
      "Epoch 8/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0309\n",
      "Epoch 9/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0307\n",
      "Epoch 10/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0307\n",
      "Epoch 11/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0306\n",
      "Epoch 12/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0305\n",
      "Epoch 13/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0304\n",
      "Epoch 14/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0303\n",
      "Epoch 15/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0303\n",
      "Epoch 16/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0302\n",
      "Epoch 17/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0302\n",
      "Epoch 18/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0301\n",
      "Epoch 19/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0301\n",
      "Epoch 20/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0301\n",
      "Epoch 21/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0300\n",
      "Epoch 22/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0300\n",
      "Epoch 23/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0299\n",
      "Epoch 24/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0299\n",
      "Epoch 25/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0299\n",
      "Epoch 26/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0299\n",
      "Epoch 27/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0298\n",
      "Epoch 28/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0298\n",
      "Epoch 29/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0298\n",
      "Epoch 30/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0297\n",
      "Epoch 31/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0297\n",
      "Epoch 32/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0297\n",
      "Epoch 33/10000\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0296\n",
      "Epoch 34/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0296\n",
      "Epoch 35/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0296\n",
      "Epoch 36/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0296\n",
      "Epoch 37/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0296\n",
      "Epoch 38/10000\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0295\n",
      "Epoch 39/10000\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0295\n",
      "Epoch 40/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0295\n",
      "Epoch 41/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0295\n",
      "Epoch 42/10000\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0295\n",
      "Epoch 43/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0294\n",
      "Epoch 44/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0294\n",
      "Epoch 45/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0294\n",
      "Epoch 46/10000\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0294\n",
      "Epoch 47/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0294\n",
      "Epoch 48/10000\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0294\n",
      "Epoch 49/10000\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0293\n",
      "Epoch 50/10000\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0293\n",
      "Epoch 51/10000\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0293\n",
      "Epoch 52/10000\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0293\n",
      "Epoch 53/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0293\n",
      "Epoch 54/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0292\n",
      "Epoch 55/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0293\n",
      "Epoch 56/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0292\n",
      "Epoch 57/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0292\n",
      "Epoch 58/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0292\n",
      "Epoch 59/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0292\n",
      "Epoch 60/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0292\n",
      "Epoch 61/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0292\n",
      "Epoch 62/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0291\n",
      "Epoch 63/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0291\n",
      "Epoch 64/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0291\n",
      "Epoch 65/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0291\n",
      "Epoch 66/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0291\n",
      "Epoch 67/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0291\n",
      "Epoch 68/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0290\n",
      "Epoch 69/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0290\n",
      "Epoch 70/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0290\n",
      "Epoch 71/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0290\n",
      "Epoch 72/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0290\n",
      "Epoch 73/10000\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0290\n",
      "Epoch 74/10000\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0290\n",
      "Epoch 75/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0290\n",
      "Epoch 76/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0290\n",
      "Epoch 77/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0289\n",
      "Epoch 78/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0289\n",
      "Epoch 79/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0289\n",
      "Epoch 80/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0289\n",
      "Epoch 81/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0289\n",
      "Epoch 82/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0289\n",
      "Epoch 83/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0289\n",
      "Epoch 84/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0288\n",
      "Epoch 85/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0288\n",
      "Epoch 86/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0288\n",
      "Epoch 87/10000\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0288\n",
      "Epoch 88/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0288\n",
      "Epoch 89/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0288\n",
      "Epoch 90/10000\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0288\n",
      "Epoch 91/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0288\n",
      "Epoch 92/10000\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0288\n",
      "Epoch 93/10000\n",
      "60000/60000 [==============================] - 283s 5ms/step - loss: 0.0288\n",
      "Epoch 94/10000\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0288\n",
      "Epoch 95/10000\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0288\n",
      "Epoch 96/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0288\n",
      "Epoch 97/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0287\n",
      "Epoch 98/10000\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0287\n",
      "Epoch 99/10000\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0287\n",
      "Epoch 100/10000\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0287\n",
      "Epoch 101/10000\n",
      "50880/60000 [========================>.....] - ETA: 43s - loss: 0.0286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1c11b345a87f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_noisy\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train_noisy , x_train , verbose = 1 , epochs = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save('denoising-autenc.h5')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
